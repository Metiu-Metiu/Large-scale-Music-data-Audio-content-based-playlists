{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrX5czj/dIwDVcKbXhJlzy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Access MusAV/audio_chunks from my Google Drive's \"shared with me\" folder"],"metadata":{"id":"dCZ4Fah_-ScQ"}},{"cell_type":"code","source":["!pip install essentia-tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VY66FJpDrcJl","outputId":"8e22ad20-116b-440b-b889-75e4dba6412f","executionInfo":{"status":"ok","timestamp":1676389961970,"user_tz":-60,"elapsed":23567,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting essentia-tensorflow\n","  Downloading essentia_tensorflow-2.1b6.dev858-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291.4 MB)\n","\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/291.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:01:17\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Exception:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n","    yield\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n","    data = self._fp.read(amt) if not fp_closed else b\"\"\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n","    data = self.__fp.read(amt)\n","  File \"/usr/lib/python3.8/http/client.py\", line 459, in read\n","    n = self.readinto(b)\n","  File \"/usr/lib/python3.8/http/client.py\", line 503, in readinto\n","    n = self.fp.readinto(b)\n","  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n","    return self._sock.recv_into(b)\n","  File \"/usr/lib/python3.8/ssl.py\", line 1241, in recv_into\n","    return self.read(nbytes, buffer)\n","  File \"/usr/lib/python3.8/ssl.py\", line 1099, in read\n","    return self._sslobj.read(len, buffer)\n","socket.timeout: The read operation timed out\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 167, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 339, in run\n","    requirement_set = resolver.resolve(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 94, in resolve\n","    result = self._result = resolver.resolve(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n","    state = resolution.resolve(requirements, max_rounds=max_rounds)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n","    self._add_to_criteria(self.state.criteria, r, parent=None)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n","    if not criterion.candidates:\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n","    return bool(self._sequence)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n","    return any(self)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n","    return (c for c in iterator if id(c) not in self._incompatible_ids)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n","    candidate = func()\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 215, in _make_candidate_from_link\n","    self._link_candidate_cache[link] = LinkCandidate(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 288, in __init__\n","    super().__init__(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n","    self.dist = self._prepare()\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 227, in _prepare\n","    dist = self._prepare_distribution()\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 299, in _prepare_distribution\n","    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/prepare.py\", line 487, in prepare_linked_requirement\n","    return self._prepare_linked_requirement(req, parallel_builds)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/prepare.py\", line 532, in _prepare_linked_requirement\n","    local_file = unpack_url(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/prepare.py\", line 214, in unpack_url\n","    file = get_http_url(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\n","    from_path, content_type = download(link, temp_dir.path)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/network/download.py\", line 146, in __call__\n","    for chunk in chunks:\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/progress_bars.py\", line 304, in _rich_progress_bar\n","    for chunk in iterable:\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n","    for chunk in response.raw.stream(\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n","    data = self.read(amt=amt, decode_content=decode_content)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/urllib3/response.py\", line 541, in read\n","    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n","  File \"/usr/lib/python3.8/contextlib.py\", line 131, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n","    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n","pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIxUCEJi-DWr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676390111700,"user_tz":-60,"elapsed":30587,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"cffb19ad-c0b1-4b1e-841b-df230fa2858f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# Don't run this cell if !pip install essentia-tensorflow works\n","\n","# I use this when some Google servers error does not allow me to install\n","# Essentia on Google servers\n","# !wget -c https://files.pythonhosted.org/packages/28/87/46df62cc0d93b0cde76f400ec02ba210e23c177d76cdfac9a8b70c85e18c/essentia_tensorflow-2.1b6.dev858-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","\n","# If Google servers for some reasons can not download and install essentia/essentia-tensorflow,\n","# I manually downloaded the wheels package and uploaded to my Google Drive, so use that\n","!pip install '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/essentia_tensorflow-2.1b6.dev858-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbPoM4zia-9s","executionInfo":{"status":"ok","timestamp":1676390417567,"user_tz":-60,"elapsed":3768,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"49a10801-5b7b-45ae-d101-ed00970f72bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./gdrive/MyDrive/Audio and Music processing lab - assignment/essentia_tensorflow-2.1b6.dev858-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from essentia-tensorflow==2.1b6.dev858) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from essentia-tensorflow==2.1b6.dev858) (6.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.8/dist-packages (from essentia-tensorflow==2.1b6.dev858) (1.21.6)\n","essentia-tensorflow is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"]}]},{"cell_type":"code","source":["import essentia.standard\n","\n","import glob  # https://docs.python.org/3/library/glob.html   \n","import csv # https://docs.python.org/3/library/csv.html\n","import os\n","import statistics\n","from tqdm import tqdm\n","import json # get classification genre labels from DiscogsEffnet model .json file"],"metadata":{"id":"WXVDQ1etrmDC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Enter the global parent folder where the audio files to be analyzed are stored. The search for audio files is recursive. You can also change the audio file extension to be looked for."],"metadata":{"id":"0VhzrW1b_2dq"}},{"cell_type":"code","source":["'''\n","In my case the global parent folder is;\n","/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/MusAV/audio_chunks\n","'''\n","# you can change parent_folder_name as your global parent folder into which audio files will be searched recursively\n","parent_folder_name = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/MusAV/'\n","audio_file_extension = '*.mp3'\n","full_parent_folder_glob_path = str(parent_folder_name + '**/' + audio_file_extension)\n","\n","# use glob to recursively find audio files paths https://docs.python.org/3/library/glob.html\n","audio_files_pathnames = glob.glob(full_parent_folder_glob_path, recursive=True)\n","print(f'Found {len(audio_files_pathnames)} audio chunks files paths')\n","'''\n","unique_audio_files_pathnames = set(audio_files_pathnames)\n","print(f'Found {len(unique_audio_files_pathnames)} unique audio chunks files paths')\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"wdXt-JQuACra","executionInfo":{"status":"ok","timestamp":1676390630588,"user_tz":-60,"elapsed":184285,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"91d16451-975c-4f7a-dd7c-090bfd1a0226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2100 audio chunks files paths\n"]},{"output_type":"execute_result","data":{"text/plain":["\"\\nunique_audio_files_pathnames = set(audio_files_pathnames)\\nprint(f'Found {len(unique_audio_files_pathnames)} unique audio chunks files paths')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# enter path of Discogs-Effnet model file path\n","discogsEffnet_model_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/ML Essentia models/Discogs-Effnet models/discogs-effnet-bs64-1.pb'\n","# enter path of Discogs-Effnet json file path for extracting genres labels names\n","discogsEffnet_json_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/ML Essentia models/Discogs-Effnet models/discogs-effnet-bs64-1.json'\n","# enter path of Voice/instrumental model file path\n","voiceInstr_model_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/ML Essentia models/Voice_Instrumental models/voice_instrumental-musicnn-msd-1.pb'\n","# enter path of Arousal/Valence model file path\n","vGG_embeddings_model_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/ML Essentia models/Arousal_Valence models/audioset-vggish-3.pb'\n","arousalValence_model_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/ML Essentia models/Arousal_Valence models/emomusic-vggish-audioset-1.pb'"],"metadata":{"id":"arX1K0FKavmY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# look into the DiscogsEffnet .json file, retrieve the names of the genre classes\n","# and store them into a set\n","discogsEffnet_json_file = open(discogsEffnet_json_file_path)\n","discogsEffnet_json_file_data = json.load(discogsEffnet_json_file)\n","discogsEffnet_genre_classes = []\n","for i in discogsEffnet_json_file_data['classes']:\n","    discogsEffnet_genre_classes.append(i)\n","discogsEffnet_json_file.close()\n","print(f'Found {len(discogsEffnet_genre_classes)} genre classes in DiscogsEffent model .json file.')\n","print(discogsEffnet_genre_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4VD9TQm4C4U","executionInfo":{"status":"ok","timestamp":1676390676160,"user_tz":-60,"elapsed":1375,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"7503fd75-aee5-41b9-d34e-dcb568e6191b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400 genre classes in DiscogsEffent model .json file.\n","['Blues---Boogie Woogie', 'Blues---Chicago Blues', 'Blues---Country Blues', 'Blues---Delta Blues', 'Blues---Electric Blues', 'Blues---Harmonica Blues', 'Blues---Jump Blues', 'Blues---Louisiana Blues', 'Blues---Modern Electric Blues', 'Blues---Piano Blues', 'Blues---Rhythm & Blues', 'Blues---Texas Blues', 'Brass & Military---Brass Band', 'Brass & Military---Marches', 'Brass & Military---Military', \"Children's---Educational\", \"Children's---Nursery Rhymes\", \"Children's---Story\", 'Classical---Baroque', 'Classical---Choral', 'Classical---Classical', 'Classical---Contemporary', 'Classical---Impressionist', 'Classical---Medieval', 'Classical---Modern', 'Classical---Neo-Classical', 'Classical---Neo-Romantic', 'Classical---Opera', 'Classical---Post-Modern', 'Classical---Renaissance', 'Classical---Romantic', 'Electronic---Abstract', 'Electronic---Acid', 'Electronic---Acid House', 'Electronic---Acid Jazz', 'Electronic---Ambient', 'Electronic---Bassline', 'Electronic---Beatdown', 'Electronic---Berlin-School', 'Electronic---Big Beat', 'Electronic---Bleep', 'Electronic---Breakbeat', 'Electronic---Breakcore', 'Electronic---Breaks', 'Electronic---Broken Beat', 'Electronic---Chillwave', 'Electronic---Chiptune', 'Electronic---Dance-pop', 'Electronic---Dark Ambient', 'Electronic---Darkwave', 'Electronic---Deep House', 'Electronic---Deep Techno', 'Electronic---Disco', 'Electronic---Disco Polo', 'Electronic---Donk', 'Electronic---Downtempo', 'Electronic---Drone', 'Electronic---Drum n Bass', 'Electronic---Dub', 'Electronic---Dub Techno', 'Electronic---Dubstep', 'Electronic---Dungeon Synth', 'Electronic---EBM', 'Electronic---Electro', 'Electronic---Electro House', 'Electronic---Electroclash', 'Electronic---Euro House', 'Electronic---Euro-Disco', 'Electronic---Eurobeat', 'Electronic---Eurodance', 'Electronic---Experimental', 'Electronic---Freestyle', 'Electronic---Future Jazz', 'Electronic---Gabber', 'Electronic---Garage House', 'Electronic---Ghetto', 'Electronic---Ghetto House', 'Electronic---Glitch', 'Electronic---Goa Trance', 'Electronic---Grime', 'Electronic---Halftime', 'Electronic---Hands Up', 'Electronic---Happy Hardcore', 'Electronic---Hard House', 'Electronic---Hard Techno', 'Electronic---Hard Trance', 'Electronic---Hardcore', 'Electronic---Hardstyle', 'Electronic---Hi NRG', 'Electronic---Hip Hop', 'Electronic---Hip-House', 'Electronic---House', 'Electronic---IDM', 'Electronic---Illbient', 'Electronic---Industrial', 'Electronic---Italo House', 'Electronic---Italo-Disco', 'Electronic---Italodance', 'Electronic---Jazzdance', 'Electronic---Juke', 'Electronic---Jumpstyle', 'Electronic---Jungle', 'Electronic---Latin', 'Electronic---Leftfield', 'Electronic---Makina', 'Electronic---Minimal', 'Electronic---Minimal Techno', 'Electronic---Modern Classical', 'Electronic---Musique Concrète', 'Electronic---Neofolk', 'Electronic---New Age', 'Electronic---New Beat', 'Electronic---New Wave', 'Electronic---Noise', 'Electronic---Nu-Disco', 'Electronic---Power Electronics', 'Electronic---Progressive Breaks', 'Electronic---Progressive House', 'Electronic---Progressive Trance', 'Electronic---Psy-Trance', 'Electronic---Rhythmic Noise', 'Electronic---Schranz', 'Electronic---Sound Collage', 'Electronic---Speed Garage', 'Electronic---Speedcore', 'Electronic---Synth-pop', 'Electronic---Synthwave', 'Electronic---Tech House', 'Electronic---Tech Trance', 'Electronic---Techno', 'Electronic---Trance', 'Electronic---Tribal', 'Electronic---Tribal House', 'Electronic---Trip Hop', 'Electronic---Tropical House', 'Electronic---UK Garage', 'Electronic---Vaporwave', 'Folk, World, & Country---African', 'Folk, World, & Country---Bluegrass', 'Folk, World, & Country---Cajun', 'Folk, World, & Country---Canzone Napoletana', 'Folk, World, & Country---Catalan Music', 'Folk, World, & Country---Celtic', 'Folk, World, & Country---Country', 'Folk, World, & Country---Fado', 'Folk, World, & Country---Flamenco', 'Folk, World, & Country---Folk', 'Folk, World, & Country---Gospel', 'Folk, World, & Country---Highlife', 'Folk, World, & Country---Hillbilly', 'Folk, World, & Country---Hindustani', 'Folk, World, & Country---Honky Tonk', 'Folk, World, & Country---Indian Classical', 'Folk, World, & Country---Laïkó', 'Folk, World, & Country---Nordic', 'Folk, World, & Country---Pacific', 'Folk, World, & Country---Polka', 'Folk, World, & Country---Raï', 'Folk, World, & Country---Romani', 'Folk, World, & Country---Soukous', 'Folk, World, & Country---Séga', 'Folk, World, & Country---Volksmusik', 'Folk, World, & Country---Zouk', 'Folk, World, & Country---Éntekhno', 'Funk / Soul---Afrobeat', 'Funk / Soul---Boogie', 'Funk / Soul---Contemporary R&B', 'Funk / Soul---Disco', 'Funk / Soul---Free Funk', 'Funk / Soul---Funk', 'Funk / Soul---Gospel', 'Funk / Soul---Neo Soul', 'Funk / Soul---New Jack Swing', 'Funk / Soul---P.Funk', 'Funk / Soul---Psychedelic', 'Funk / Soul---Rhythm & Blues', 'Funk / Soul---Soul', 'Funk / Soul---Swingbeat', 'Funk / Soul---UK Street Soul', 'Hip Hop---Bass Music', 'Hip Hop---Boom Bap', 'Hip Hop---Bounce', 'Hip Hop---Britcore', 'Hip Hop---Cloud Rap', 'Hip Hop---Conscious', 'Hip Hop---Crunk', 'Hip Hop---Cut-up/DJ', 'Hip Hop---DJ Battle Tool', 'Hip Hop---Electro', 'Hip Hop---G-Funk', 'Hip Hop---Gangsta', 'Hip Hop---Grime', 'Hip Hop---Hardcore Hip-Hop', 'Hip Hop---Horrorcore', 'Hip Hop---Instrumental', 'Hip Hop---Jazzy Hip-Hop', 'Hip Hop---Miami Bass', 'Hip Hop---Pop Rap', 'Hip Hop---Ragga HipHop', 'Hip Hop---RnB/Swing', 'Hip Hop---Screw', 'Hip Hop---Thug Rap', 'Hip Hop---Trap', 'Hip Hop---Trip Hop', 'Hip Hop---Turntablism', 'Jazz---Afro-Cuban Jazz', 'Jazz---Afrobeat', 'Jazz---Avant-garde Jazz', 'Jazz---Big Band', 'Jazz---Bop', 'Jazz---Bossa Nova', 'Jazz---Contemporary Jazz', 'Jazz---Cool Jazz', 'Jazz---Dixieland', 'Jazz---Easy Listening', 'Jazz---Free Improvisation', 'Jazz---Free Jazz', 'Jazz---Fusion', 'Jazz---Gypsy Jazz', 'Jazz---Hard Bop', 'Jazz---Jazz-Funk', 'Jazz---Jazz-Rock', 'Jazz---Latin Jazz', 'Jazz---Modal', 'Jazz---Post Bop', 'Jazz---Ragtime', 'Jazz---Smooth Jazz', 'Jazz---Soul-Jazz', 'Jazz---Space-Age', 'Jazz---Swing', 'Latin---Afro-Cuban', 'Latin---Baião', 'Latin---Batucada', 'Latin---Beguine', 'Latin---Bolero', 'Latin---Boogaloo', 'Latin---Bossanova', 'Latin---Cha-Cha', 'Latin---Charanga', 'Latin---Compas', 'Latin---Cubano', 'Latin---Cumbia', 'Latin---Descarga', 'Latin---Forró', 'Latin---Guaguancó', 'Latin---Guajira', 'Latin---Guaracha', 'Latin---MPB', 'Latin---Mambo', 'Latin---Mariachi', 'Latin---Merengue', 'Latin---Norteño', 'Latin---Nueva Cancion', 'Latin---Pachanga', 'Latin---Porro', 'Latin---Ranchera', 'Latin---Reggaeton', 'Latin---Rumba', 'Latin---Salsa', 'Latin---Samba', 'Latin---Son', 'Latin---Son Montuno', 'Latin---Tango', 'Latin---Tejano', 'Latin---Vallenato', 'Non-Music---Audiobook', 'Non-Music---Comedy', 'Non-Music---Dialogue', 'Non-Music---Education', 'Non-Music---Field Recording', 'Non-Music---Interview', 'Non-Music---Monolog', 'Non-Music---Poetry', 'Non-Music---Political', 'Non-Music---Promotional', 'Non-Music---Radioplay', 'Non-Music---Religious', 'Non-Music---Spoken Word', 'Pop---Ballad', 'Pop---Bollywood', 'Pop---Bubblegum', 'Pop---Chanson', 'Pop---City Pop', 'Pop---Europop', 'Pop---Indie Pop', 'Pop---J-pop', 'Pop---K-pop', 'Pop---Kayōkyoku', 'Pop---Light Music', 'Pop---Music Hall', 'Pop---Novelty', 'Pop---Parody', 'Pop---Schlager', 'Pop---Vocal', 'Reggae---Calypso', 'Reggae---Dancehall', 'Reggae---Dub', 'Reggae---Lovers Rock', 'Reggae---Ragga', 'Reggae---Reggae', 'Reggae---Reggae-Pop', 'Reggae---Rocksteady', 'Reggae---Roots Reggae', 'Reggae---Ska', 'Reggae---Soca', 'Rock---AOR', 'Rock---Acid Rock', 'Rock---Acoustic', 'Rock---Alternative Rock', 'Rock---Arena Rock', 'Rock---Art Rock', 'Rock---Atmospheric Black Metal', 'Rock---Avantgarde', 'Rock---Beat', 'Rock---Black Metal', 'Rock---Blues Rock', 'Rock---Brit Pop', 'Rock---Classic Rock', 'Rock---Coldwave', 'Rock---Country Rock', 'Rock---Crust', 'Rock---Death Metal', 'Rock---Deathcore', 'Rock---Deathrock', 'Rock---Depressive Black Metal', 'Rock---Doo Wop', 'Rock---Doom Metal', 'Rock---Dream Pop', 'Rock---Emo', 'Rock---Ethereal', 'Rock---Experimental', 'Rock---Folk Metal', 'Rock---Folk Rock', 'Rock---Funeral Doom Metal', 'Rock---Funk Metal', 'Rock---Garage Rock', 'Rock---Glam', 'Rock---Goregrind', 'Rock---Goth Rock', 'Rock---Gothic Metal', 'Rock---Grindcore', 'Rock---Grunge', 'Rock---Hard Rock', 'Rock---Hardcore', 'Rock---Heavy Metal', 'Rock---Indie Rock', 'Rock---Industrial', 'Rock---Krautrock', 'Rock---Lo-Fi', 'Rock---Lounge', 'Rock---Math Rock', 'Rock---Melodic Death Metal', 'Rock---Melodic Hardcore', 'Rock---Metalcore', 'Rock---Mod', 'Rock---Neofolk', 'Rock---New Wave', 'Rock---No Wave', 'Rock---Noise', 'Rock---Noisecore', 'Rock---Nu Metal', 'Rock---Oi', 'Rock---Parody', 'Rock---Pop Punk', 'Rock---Pop Rock', 'Rock---Pornogrind', 'Rock---Post Rock', 'Rock---Post-Hardcore', 'Rock---Post-Metal', 'Rock---Post-Punk', 'Rock---Power Metal', 'Rock---Power Pop', 'Rock---Power Violence', 'Rock---Prog Rock', 'Rock---Progressive Metal', 'Rock---Psychedelic Rock', 'Rock---Psychobilly', 'Rock---Pub Rock', 'Rock---Punk', 'Rock---Rock & Roll', 'Rock---Rockabilly', 'Rock---Shoegaze', 'Rock---Ska', 'Rock---Sludge Metal', 'Rock---Soft Rock', 'Rock---Southern Rock', 'Rock---Space Rock', 'Rock---Speed Metal', 'Rock---Stoner Rock', 'Rock---Surf', 'Rock---Symphonic Rock', 'Rock---Technical Death Metal', 'Rock---Thrash', 'Rock---Twist', 'Rock---Viking Metal', 'Rock---Yé-Yé', 'Stage & Screen---Musical', 'Stage & Screen---Score', 'Stage & Screen---Soundtrack', 'Stage & Screen---Theme']\n"]}]},{"cell_type":"code","source":["# enter path of *.csv file where data will be dumped\n","# If file does not exist already, it will be created\n","csv_data_file_path = '/content/gdrive/MyDrive/Audio and Music processing lab - assignment/Task 2/MusAV - audio_chunks - data.csv'\n","\n","# Since I am going to dump a dictionary into each row of the .csv file,\n","# here is basically where we determine the order of the column headers\n","fieldnames = ['Audio_file_path', 'Tempo_BPM']\n","fieldnames += discogsEffnet_genre_classes\n","fieldnames += ['Voice', 'Instrumental', 'Danceability', 'Arousal', 'Valence']"],"metadata":{"id":"v22hFzE7x9zH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["did_csv_file_already_exist = os.path.isfile(csv_data_file_path)\n","# open the file in the append mode, so that it is not truncated every time this\n","# snippet is run. By doing so, if anything goes wrong during an execution of this\n","# code snippet, we can re-run it without starting over\n","csv_data_file_writer = open(csv_data_file_path, 'a')\n","csv_data_file_reader = open(csv_data_file_path, 'r')\n","csv_data_file_dictWriter = csv.DictWriter(csv_data_file_writer, fieldnames=fieldnames)\n","if did_csv_file_already_exist is False: # write header only if file was created right now and did not exist before\n","  print('No .csv file found at the given path. A .csv file has been created at the given path.')\n","  csv_data_file_dictWriter.writeheader()\n","else:\n","    print('.csv file found at the given path.')\n","# create a csv.DictReader and also create a set (containing unique values)\n","# data structure out of the values of the first field ('audio_file_path'), so that,\n","# when writing, we can check first whether each row is already present or not in the .csv file\n","csv_data_file_dictReader = csv.DictReader(csv_data_file_reader)\n","csv_data_file_already_existing_paths = set()\n","for row in csv_data_file_dictReader:\n","   this_row_dict = dict(row) # create a dictionary out of this row\n","   csv_data_file_already_existing_paths.add(this_row_dict['audio_file_path']) # add the value corresponding to the audio_file_path key to a set\n","print(f'{len(csv_data_file_already_existing_paths)} file paths already present in the .csv file. These files will not be analyzed ')\n","# print(csv_data_file_already_existing_paths)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlS7nLAge9cO","executionInfo":{"status":"ok","timestamp":1676390685022,"user_tz":-60,"elapsed":3,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"d1f83a4f-e4bc-487c-bde7-957e75213bd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No .csv file found at the given path. A .csv file has been created at the given path.\n","0 file paths already present in the .csv file. These files will not be analyzed \n"]}]},{"cell_type":"markdown","source":["ONLY FOR TEST PURPOSES, I DEFINE A BATCH SIZE IN ORDER TO RUN SCRIPTS FASTER WHEN I ONLY NEED TO TEST THE EXECUTION OF A FEW EXTRACTIONS"],"metadata":{"id":"ydfP_1wZZVy0"}},{"cell_type":"code","source":["# batch_size = len(audio_files_pathnames) - 1\n","batch_size = 10\n","\n","# to make things easier for managing the Pandas' DataFrame later,\n","# I change the audio path to make it relative to the .py script for the Streamlit interface\n","# I will use the audio file paths as index of the DataFrame\n","def get_relative_path(audio_chunk_path): # takes the Google Drive path of a file and adapts it to relative path from this .py file\n","    return 'audio/' + audio_chunk_path[94:]"],"metadata":{"id":"ov_TQ58KZexi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# instantiate any extractor or TensorFlow model only once for all audio files,\n","# rather than once for each audio file\n","effnetDiscogs_model = essentia.standard.TensorflowPredictEffnetDiscogs(graphFilename=discogsEffnet_model_file_path)\n","voiceInstr_model = essentia.standard.TensorflowPredictMusiCNN(graphFilename=voiceInstr_model_file_path)\n","danceability_algo = essentia.standard.Danceability()\n","\n","# Arousal/valence VGGish model\n","aV_inputLayerName = 'flatten_in_input'\n","aV_outputLayerName = 'dense_out'\n","embeddings_model = essentia.standard.TensorflowPredictVGGish(\n","    graphFilename = vGG_embeddings_model_file_path,\n","    input = 'model/Placeholder',\n","    output = 'model/vggish/embeddings')\n","\n","av_model = essentia.standard.TensorflowPredict2D(\n","  graphFilename = arousalValence_model_file_path,\n","  input=  aV_inputLayerName,\n","  output = aV_outputLayerName)"],"metadata":{"id":"8nmxRUGO1yU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counter = 0\n","for audio_file_path in tqdm(audio_files_pathnames): # use tqdm progress bar functionality\n","  # add a row to the .csv file and start extracting features from an audio chunk\n","  # only if the .csv file does not already contain a row with the same file path\n","  if audio_file_path not in csv_data_file_already_existing_paths:\n","    audioSignal = essentia.standard.MonoLoader(filename=audio_file_path)()\n","\n","    rhythmExt2013 = essentia.standard.RhythmExtractor2013(method=\"multifeature\")\n","    bpm, beats, beats_confidence, _, beats_intervals = rhythmExt2013(audioSignal)\n","\n","    effnetDiscogs_activations = effnetDiscogs_model(audioSignal)\n","    # print(f'Shape of effnetDiscogs_activations is {effnetDiscogs_activations.shape}')\n","    # effnetDiscogs_activations.shape is 82 * 400, 400 being the activations\n","    # so, for each column, we have to average over all 82 rows\n","    effnetDiscogs_activations_mean = []\n","    for activation_it in range(400):\n","      effnetDiscogs_activations_mean.append(statistics.mean(effnetDiscogs_activations[:,activation_it]))\n","    # print(f'The array containing the means of the Discogs-effnet activations is {len(effnetDiscogs_activations_mean)} items long')\n","\n","    voiceInstr_activations = voiceInstr_model(audioSignal)\n","    # print(f'Shape of voiceInstr_activations is {voiceInstr_activations.shape}')\n","    # voiceInstr_activations.shape is 54 * 2, 2 being the activations\n","    voiceInstr_activations_mean = []\n","    for activation_it in range(2):\n","      voiceInstr_activations_mean.append(statistics.mean(voiceInstr_activations[:,activation_it]))\n","    # print(f'The array containing the means of the Voice/Instrumental activations is {len(voiceInstr_activations_mean)} items long')\n","\n","    danceability, DFA = danceability_algo(audioSignal)\n","\n","    # Arousal/valence model\n","    embeddings = embeddings_model(audioSignal)    \n","    av_activations = av_model(embeddings)\n","    # print(f'Arousal and valence activations have size; {av_activations.shape}')\n","    # av_activations.shape is 88 * 2, 88 being the time frames\n","    av_activations_mean = []\n","    for activation_it in range(2):\n","      av_activations_mean.append(statistics.mean(av_activations[:,activation_it]))\n","\n","    file_features_dict = {             'Audio_file_path': get_relative_path(audio_file_path),\n","                                       'Tempo_BPM': bpm,\n","                                       'Voice': voiceInstr_activations_mean[0],\n","                                       'Instrumental': voiceInstr_activations_mean[1],\n","                                       'Danceability': danceability,\n","                                       'Arousal' : av_activations_mean[0],\n","                                       'Valence' : av_activations_mean[1]}\n","    file_features_dict.update(dict(zip(discogsEffnet_genre_classes, effnetDiscogs_activations_mean)))\n","    csv_data_file_dictWriter.writerow(file_features_dict)\n","    \n","    counter += 1\n","\n","print(f'{counter} file analyzed out of {len(audio_files_pathnames)} files paths.')\n","\n","# close the file\n","csv_data_file_reader.close()\n","csv_data_file_writer.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":635},"id":"YoKOt-VbfHR5","executionInfo":{"status":"error","timestamp":1676390881030,"user_tz":-60,"elapsed":88773,"user":{"displayName":"MATTEO FABBRI","userId":"11369581659480367990"}},"outputId":"0fec39b5-21f2-4471-aa0b-5011c4908d14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 1/2100 [00:05<3:01:53,  5.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 2/2100 [00:10<3:00:55,  5.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 3/2100 [00:15<3:04:04,  5.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 4/2100 [00:22<3:25:28,  5.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 5/2100 [00:27<3:15:55,  5.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 6/2100 [00:33<3:17:48,  5.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 7/2100 [00:38<3:12:22,  5.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 8/2100 [00:45<3:25:10,  5.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 9/2100 [00:51<3:25:50,  5.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 10/2100 [00:57<3:31:39,  6.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 11/2100 [01:03<3:31:50,  6.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 12/2100 [01:09<3:29:27,  6.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 13/2100 [01:15<3:23:56,  5.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 14/2100 [01:20<3:19:42,  5.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 15/2100 [01:26<3:24:23,  5.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Arousal and valence activations have size; (88, 2)\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 15/2100 [01:28<3:23:55,  5.87s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-264fd3316676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maudioSignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0messentia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonoLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrhythmExt2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0messentia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRhythmExtractor2013\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multifeature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeats_confidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeats_intervals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhythmExt2013\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudioSignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/essentia/standard.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# init the internal cpp wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0m_essentia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# configure the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}